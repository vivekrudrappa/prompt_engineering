{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "JjVaYKA3E4Sh",
      "metadata": {
        "id": "JjVaYKA3E4Sh"
      },
      "source": [
        "# __Demo: Zero-Shot Prompting with OpenAI__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L5xEJAD-FWkJ",
      "metadata": {
        "id": "L5xEJAD-FWkJ"
      },
      "source": [
        "## __Steps to Perform:__\n",
        "Step 1: Set up the OpenAI API Key\n",
        "\n",
        "Step 2: Define a Function to Get Completion\n",
        "\n",
        "Step 3: Define Your Prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oejbW3zZlqXB",
      "metadata": {
        "id": "oejbW3zZlqXB"
      },
      "source": [
        "### __Step 1: Set up the OpenAI API Key__\n",
        "- The code imports the necessary libraries.\n",
        "- The **os** is used for interacting with the operating system, and __openai__ is the library required to work with OpenAI's API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "172a828d-22d6-486b-be55-62c9258add5b",
      "metadata": {
        "id": "172a828d-22d6-486b-be55-62c9258add5b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key  = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# local environment variable loading\n",
        "# openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Adding API key value directly\n",
        "# openai.api_key  = \"sk-klpk-R_jslfyilZyp1kdci7-y0i32VlcXkmbbbMT3BlbkFJHDrMsmVhYGcR123456XQFAeNAZqHgVA-6mYWEVTbb2_jSLAMPDcpaW09QUA\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yI8QQCxCl-LQ",
      "metadata": {
        "id": "yI8QQCxCl-LQ"
      },
      "source": [
        "### __Step 2: Define a Function to Get Completion__\n",
        "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
        "\n",
        "__Parameters:__\n",
        "  - __prompt__: It is the text input for which the model will generate a completion.\n",
        "  -  __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
        "\n",
        "The __openai.chat.completions.create__ function is used to send a request to the OpenAI API.\n",
        "- This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a",
      "metadata": {
        "id": "e778a5d4-77e5-4d61-a77d-3fed1e8d830a"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.5,\n",
        "        max_tokens=512\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XJS0DNh0nonO",
      "metadata": {
        "id": "XJS0DNh0nonO"
      },
      "source": [
        "### __Step 3: Define Your Prompt__\n",
        "- The prompt variable is defined with a simple translation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
      "metadata": {
        "id": "3ef6aa68-a8aa-45c6-b70b-3060e9253b90",
        "outputId": "3fbcbc3f-92c8-4076-d681-9377c94f41f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero shot prompting is a technique used in machine learning where a model is given a prompt or task without any examples or training data related to that specific prompt. The model is expected to generate a response or output based on its pre-existing knowledge and understanding of the language.\n",
            "\n",
            "In zero shot prompting, the model is not explicitly trained on the prompt or task at hand, but rather uses its general knowledge and language understanding to generate a response. This can be useful in scenarios where there is limited or no training data available for a specific task, or when the model needs to generalize to new tasks or prompts.\n",
            "\n",
            "Zero shot prompting can be challenging as the model may not have specific examples or data to rely on for generating accurate responses. However, with advancements in natural language processing and pre-trained language models, zero shot prompting has become more feasible and effective in various applications such as text generation, question answering, and language translation.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Explain Zero Shot Prompting\"\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f442b52c-c41e-4e9a-ba68-8fbeb3a83efb",
      "metadata": {
        "id": "f442b52c-c41e-4e9a-ba68-8fbeb3a83efb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfe1cd0-2508-40df-ac7c-e6d6dbfd793f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of the United States of America is Washington, D.C.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is the capital of USA?\"\n",
        "response = get_completion(prompt)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLonMf8nMEWU"
      },
      "id": "NLonMf8nMEWU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 [3.10]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}