{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33679ce2-9df6-4bc5-b875-953500b0cdc0",
      "metadata": {
        "id": "33679ce2-9df6-4bc5-b875-953500b0cdc0"
      },
      "source": [
        "# __Demo: Few-Shot Prompting with OpenAI__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884ce215-54cf-4a8f-8177-9189423a412c",
      "metadata": {
        "id": "884ce215-54cf-4a8f-8177-9189423a412c"
      },
      "source": [
        "## __Steps to Perform:__\n",
        "Step 1: Set up the OpenAI API Key\n",
        "\n",
        "Step 2: Define a Function to Get Completion\n",
        "\n",
        "Step 3: Define Your Prompt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17522620-a9f9-46af-9293-c81e63442bc1",
      "metadata": {
        "id": "17522620-a9f9-46af-9293-c81e63442bc1"
      },
      "source": [
        "### __Step 1: Set up the OpenAI API Key__\n",
        "\n",
        "- The code imports the necessary libraries.\n",
        "- The __os__ is used for interacting with the operating system, and __openai__ is the library required to work with OpenAI's API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c86a56-9cb2-4759-aabf-5136dd059077",
      "metadata": {
        "id": "39c86a56-9cb2-4759-aabf-5136dd059077"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai.api_key  = userdata.get('OPENAI_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qU8nqzWMJb1g",
      "metadata": {
        "id": "qU8nqzWMJb1g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e877b6ac-1a14-4535-b38a-2502f02abc33",
      "metadata": {
        "id": "e877b6ac-1a14-4535-b38a-2502f02abc33"
      },
      "source": [
        "### __Step 2: Define a Function to Get Completion__\n",
        "The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.\n",
        "\n",
        "__Parameters:__\n",
        "\n",
        "- __prompt__: It is the text input for which the model will generate a completion.\n",
        "- __model__: The gpt-3.5-turbo model is used to perform the tasks.\n",
        "\n",
        "The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.\n",
        "\n",
        "This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc464f8a-f318-4097-91c9-fd1fded34969",
      "metadata": {
        "id": "bc464f8a-f318-4097-91c9-fd1fded34969"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a5d4ecd-b78a-457a-8629-dc58d97c3eaf",
      "metadata": {
        "id": "2a5d4ecd-b78a-457a-8629-dc58d97c3eaf"
      },
      "source": [
        "### __Step 3: Define Your Prompts__\n",
        "- The prompt consists of several pieces of customer feedback, each followed by a classification (Positive, Negative, or Neutral).\n",
        "- These examples serve to teach the model what kind of output is expected.\n",
        "- The final feedback statement is the new instance for which the classification is sought."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53df046c-65ce-4385-8e60-b5af439567ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53df046c-65ce-4385-8e60-b5af439567ca",
        "outputId": "a7f50787-143f-44b4-8825-4ce8f0296d09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great to hear that you were satisfied with our customer support! This is a Positive sentiment.\n",
            "Score: 0.8\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Feedback: \"I loved the quick service and friendly staff.\"\n",
        "Classification: Great we are delighed to have a Positive sentiment\n",
        "Score : 0.9\n",
        "\n",
        "Feedback: \"The product did not meet my expectations.\"\n",
        "Classification: Oops, we are afraid its a Negative sentiment\n",
        "Score : 0.2\n",
        "\n",
        "Feedback: \"I am not sure if this is the right product for me.\"\n",
        "Classification: We will try to improve and satisfy you next time as its a Neutral sentiment.\n",
        "Score : 0.5\n",
        "\n",
        "Feedback: \"Your customer support was helpful, very satisfied.\"\n",
        "Classification:\n",
        "Score:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be51fd93-ba12-4cc7-ae8b-b80aa2a5b41b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be51fd93-ba12-4cc7-ae8b-b80aa2a5b41b",
        "outputId": "99fd1ceb-4b6a-4163-de9b-2c24b70bd90c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"The United States of America shall endure forever.\", Washington D.C.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "Q: What is the capital of Italy?\n",
        "A: \"Imperium Romanum in aeternum stabit.\", Rome\n",
        "\n",
        "Q: What is the capital of France?\n",
        "A: \"L'Empire romain devrait tenir pour l'éternité.\", Paris\n",
        "\n",
        "Q: What is the capital of Japan?\n",
        "A: \"日本は永遠に生き続けるべきです。\", Tokyo\n",
        "\n",
        "Q: What is the capital of Germany?\n",
        "A: \"Das Deutsche Reich sollte für immer bestehen.\", Berlin\n",
        "\n",
        "Q: What is the capital of Brazil?\n",
        "A: \"O Império Brasileiro deve durar para sempre.\", Brasília\n",
        "\n",
        "Q: What is the capital of USA?\n",
        "A:\n",
        "\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecaeb9b3-9c36-47b7-b720-b68f6f3d7a87",
      "metadata": {
        "id": "ecaeb9b3-9c36-47b7-b720-b68f6f3d7a87",
        "outputId": "95d6e29a-f5dc-4a7f-8cf2-22259a1c2f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Renew Your Subscription Now and Keep Enjoying!\"\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"\n",
        "Task: Generate a subject line for the following emails.\n",
        "\n",
        "Email: \"Thank you for your purchase! Your order has been shipped and will arrive in 3-5 business days.\"\n",
        "Subject: \"Your Order Has been Shipped! Hurray\"\n",
        "\n",
        "Email: \"We noticed you left items in your cart. Don’t miss out on these great deals!\"\n",
        "Subject: \"Don’t Forget: Items Waiting in Your Cart!\"\n",
        "\n",
        "Email: \"We’ve just launched a new product line. Check out our latest arrivals and get 10% off your first purchase.\"\n",
        "Subject: \"Explore Our New Arrivals & Enjoy 10% Off!\"\n",
        "\n",
        "Email: \"Your subscription is about to expire. Renew now to continue enjoying our services.\"\n",
        "Subject:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41311957-8999-431b-8196-03626a68c44c",
      "metadata": {
        "id": "41311957-8999-431b-8196-03626a68c44c"
      },
      "source": [
        "In this few-shot scenario, the model uses the provided examples to understand the context and criteria for classification, applying that understanding to classify new, unseen feedback. This is particularly useful for more subjective tasks like sentiment analysis, where context and nuance play significant roles."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 [3.10]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}