# -*- coding: utf-8 -*-
"""Demo_API_based_Prompting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jbGVb4_6t9y8_z482sJfglr5zaCG4niy

# __Demo: Basics of OpenAI API call in python__

## __Steps to Perform:__
Step 1: Set up the OpenAI API Key

Step 2: Define a Function to Get Completion

Step 3: Define Your Prompt

### __Step 1: Set up the OpenAI API Key__
- The code imports the necessary libraries.
- The **os** is used for interacting with the operating system, and __openai__ is the library required to work with OpenAI's API.
"""

import os
import openai
from google.colab import userdata

openai.api_key  = userdata.get('OPENAI_API_KEY')

"""### __Step 2: Define a Function to Get Completion__
The __get_completion__ function is responsible for sending a prompt to the OpenAI model and receiving its response.

__Parameters:__
  - __prompt__: It is the text input for which the model will generate a completion.
  -  __model__: The gpt-3.5-turbo model is used to perform the tasks.

The __openai.ChatCompletion.create__ function is used to send a request to the OpenAI API.
- This request includes the model, the input messages (formatted as a list of dictionaries with user roles and content), and a temperature setting.
"""

def get_completion(prompt, model="gpt-3.5-turbo"):
    try:
        messages = [{"role": "user", "content": prompt}]

        response = openai.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.1,
            max_tokens=512
        )

        return response  # Return full response (not a string)

    except openai.error.OpenAIError as e:
        return {"error": f"OpenAI API Error: {str(e)}"}
    except Exception as e:
        return {"error": f"Unexpected Error: {str(e)}"}

"""Inside the above fucntion, we will discuss the Messages part first

Structure is :

**Role** --> Defining who is speaking

    System : Sets the behavious of the model
    User : Who inputs the data or instruction
    Assistant : The models's Response

Content : The actual text or instruction which is passed by us.

### __Step 3: Define Your Prompt__
- The prompt variable is defined with a simple translation task.
"""

prompt = "Explain artificial intelligence"
response = get_completion(prompt)

print(response.choices[0].message.content)

response.choices

response.choices[0]

response.choices[0].message

response.choices[0].message.content

def get_completion(prompt, model = "gpt-3.5-turbo"):

    # Create the messages list with the user prompt
    messages = [
        {"role": "system", "content": "You are a math tutor"},
        {"role": "user", "content": "Explain me the ..."},
        {"role": "assistant", "content": "The concept is like..."},
        {"role": "user", "content": prompt+"Also give me an example"},

    ]

    # Create a chat completion request
    response = openai.chat.completions.create(

        model=model,
        messages=messages,
        temperature=0.9,
        max_tokens=512

    )

    # Return the content of the response
    # instead of entire response
    return response.choices[0].message.content

prompt = "trignometry"

response_content = get_completion(prompt)
print(response_content)

prompt = "algebra"

response_content = get_completion(prompt)
print(response_content)

